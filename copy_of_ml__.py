# -*- coding: utf-8 -*-
"""Copy of ml__.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y5LFvuw80N-SS6amd_FKw_mH2VQqvQ4K
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pytorch-tabnet --quiet

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Dataset
from pytorch_tabnet.tab_model import TabNetClassifier
import pandas as pd
import numpy as np
import os
from PIL import Image
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from pytorch_tabnet.tab_model import TabNetClassifier
import numpy as np

# Load dataset
df = pd.read_csv('/content/Cardiovascular Disease dataset.csv')

print(df.columns)

# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
from pytorch_tabnet.tab_model import TabNetClassifier

# Load Dataset
df = pd.read_csv('/content/Cardiovascular Disease dataset.csv', delimiter=';')

# Basic info
print("Dataset shape:", df.shape)
print(df.head())
print(df.info())
print(df.describe())
print("Missing values:\n", df.isnull().sum())

# Target column (last column)
target_column = df.columns[-1]
print(f"Target column: {target_column}")

# Target distribution
print(df[target_column].value_counts())
print(df[target_column].value_counts(normalize=True).round(3))

# EDA - Correlation heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.tight_layout()
plt.show()

# Features and target
X = df.drop(target_column, axis=1)
y = df[target_column]

feature_names = X.columns.tolist()

# Train-test split with stratification
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Scale features - Important for TabNet (except categorical if any)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# TabNet parameters - customize as needed
tabnet_params = {
    "n_d": 16,               # Width of decision prediction layer
    "n_a": 16,               # Width of attention embedding for each mask
    "n_steps": 3,            # Number of steps in the architecture
    "gamma": 1.5,            # Feature reusage coefficient
    "lambda_sparse": 1e-3,   # Sparsity regularization
    "optimizer_fn": torch.optim.Adam,
    "optimizer_params": {"lr": 2e-2},
    "scheduler_params": {"step_size": 50, "gamma": 0.9},
    "scheduler_fn": torch.optim.lr_scheduler.StepLR,
    "mask_type": "entmax",   # sparsemax or entmax
    "seed": 42
}

# Initialize TabNet model
model = TabNetClassifier(**tabnet_params)

# Train model
model.fit(
    X_train=X_train, y_train=y_train,
    eval_set=[(X_train, y_train), (X_test, y_test)],
    eval_name=['train', 'test'],
    eval_metric=['accuracy', 'auc'],
    max_epochs=10,
    patience=10,
    batch_size=1024,
    virtual_batch_size=128,
    num_workers=0,
    drop_last=False
)

# Predict and evaluate
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.4f}")

print("Classification Report:\n", classification_report(y_test, y_pred))

model.save_model("/content/drive/MyDrive/tabnet_model")

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Disease', 'Disease'], yticklabels=['No Disease', 'Disease'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# ROC AUC
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"ROC AUC Score: {roc_auc:.4f}")

# Save model
model.save_model("tabnet_cvd_model")
print("Model saved to tabnet_cvd_model.zip")

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),  # if originally 1 channel
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),
])

train_ds = datasets.ImageFolder('/content/drive/MyDrive/ecg_dataset/train', transform=transform)
test_ds = datasets.ImageFolder('/content/drive/MyDrive/ecg_dataset/test', transform=transform)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
test_loader = DataLoader(test_ds, batch_size=32)

import torch
import torch.nn as nn
import math

class PatchEmbedding(nn.Module):
    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):
        super().__init__()
        self.img_size = img_size
        self.patch_size = patch_size
        self.grid_size = img_size // patch_size
        self.num_patches = self.grid_size ** 2

        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)
        # This Conv2d acts as patchifying + linear projection

    def forward(self, x):
        # x shape: [B, C, H, W]
        x = self.proj(x)  # [B, embed_dim, grid_size, grid_size]
        x = x.flatten(2)  # [B, embed_dim, num_patches]
        x = x.transpose(1, 2)  # [B, num_patches, embed_dim]
        return x

class Attention(nn.Module):
    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):
        super().__init__()
        self.num_heads = num_heads
        head_dim = dim // num_heads
        self.scale = head_dim ** -0.5

        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)
        self.attn_drop = nn.Dropout(attn_drop)
        self.proj = nn.Linear(dim, dim)
        self.proj_drop = nn.Dropout(proj_drop)

    def forward(self, x):
        B, N, C = x.shape
        qkv = self.qkv(x)  # [B, N, 3*C]
        qkv = qkv.reshape(B, N, 3, self.num_heads, C // self.num_heads)
        qkv = qkv.permute(2, 0, 3, 1, 4)  # 3, B, num_heads, N, head_dim

        q, k, v = qkv[0], qkv[1], qkv[2]  # each: [B, num_heads, N, head_dim]

        attn = (q @ k.transpose(-2, -1)) * self.scale  # [B, num_heads, N, N]
        attn = attn.softmax(dim=-1)
        attn = self.attn_drop(attn)

        x = (attn @ v)  # [B, num_heads, N, head_dim]
        x = x.transpose(1, 2).reshape(B, N, C)  # [B, N, C]

        x = self.proj(x)
        x = self.proj_drop(x)
        return x

class MLP(nn.Module):
    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):
        super().__init__()
        out_features = out_features or in_features
        hidden_features = hidden_features or in_features
        self.fc1 = nn.Linear(in_features, hidden_features)
        self.act = nn.GELU()
        self.fc2 = nn.Linear(hidden_features, out_features)
        self.drop = nn.Dropout(drop)

    def forward(self, x):
        x = self.fc1(x)
        x = self.act(x)
        x = self.drop(x)
        x = self.fc2(x)
        x = self.drop(x)
        return x

class TransformerBlock(nn.Module):
    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0., drop_path=0.):
        super().__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)
        self.norm2 = nn.LayerNorm(dim)
        mlp_hidden_dim = int(dim * mlp_ratio)
        self.mlp = MLP(dim, hidden_features=mlp_hidden_dim, drop=drop)

    def forward(self, x):
        x = x + self.attn(self.norm1(x))
        x = x + self.mlp(self.norm2(x))
        return x

class VisionTransformer(nn.Module):
    def __init__(
        self,
        img_size=224,
        patch_size=16,
        in_chans=3,
        num_classes=8,
        embed_dim=768,
        depth=12,
        num_heads=8,
        mlp_ratio=4.,
        qkv_bias=True,
        drop_rate=0.,
        attn_drop_rate=0.
    ):
        super().__init__()
        self.num_classes = num_classes
        self.embed_dim = embed_dim

        self.patch_embed = PatchEmbedding(img_size, patch_size, in_chans, embed_dim)
        num_patches = self.patch_embed.num_patches

        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))
        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))
        self.pos_drop = nn.Dropout(p=drop_rate)

        self.blocks = nn.ModuleList([
            TransformerBlock(embed_dim, num_heads, mlp_ratio, qkv_bias, drop_rate, attn_drop_rate)
            for _ in range(depth)
        ])

        self.norm = nn.LayerNorm(embed_dim)
        self.head = nn.Linear(embed_dim, num_classes)

        self._init_weights()

    def _init_weights(self):
        nn.init.trunc_normal_(self.pos_embed, std=.02)
        nn.init.trunc_normal_(self.cls_token, std=.02)
        # Initialize head bias to zero
        nn.init.zeros_(self.head.bias)

    def forward(self, x):
        B = x.shape[0]
        x = self.patch_embed(x)  # [B, num_patches, embed_dim]

        cls_tokens = self.cls_token.expand(B, -1, -1)  # [B, 1, embed_dim]
        x = torch.cat((cls_tokens, x), dim=1)  # prepend class token

        x = x + self.pos_embed
        x = self.pos_drop(x)

        for blk in self.blocks:
            x = blk(x)

        x = self.norm(x)
        cls_token_final = x[:, 0]  # take cls token representation
        out = self.head(cls_token_final)  # classification head

        return out

from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

train_dataset = ImageFolder(root='/content/drive/MyDrive/ecg_dataset/train', transform=transform)
test_dataset = ImageFolder(root='/content/drive/MyDrive/ecg_dataset/test', transform=transform)

print("Classes:", train_dataset.classes)  # ['Abnormal Heartbeat', 'History of MI', 'Myocardial Infarction', 'Normal']

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)

vit_model = VisionTransformer(
    img_size=224,
    patch_size=16,
    in_chans=3,
    num_classes=4,
    embed_dim=192,   # reduce
    depth=4,         # reduce
    num_heads=3,     # adjust for embed_dim divisibility
    mlp_ratio=2.,
)

from torch.utils.data import DataLoader
import torch.nn.functional as F
import time

def train_vit(model, train_loader, val_loader, device, epochs=10, lr=3e-4):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    model.to(device)

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        correct = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()

        train_acc = correct / len(train_loader.dataset)
        train_loss = total_loss / len(train_loader.dataset)

        # Validation
        model.eval()
        val_correct = 0
        val_loss = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * images.size(0)
                _, predicted = torch.max(outputs, 1)
                val_correct += (predicted == labels).sum().item()

        val_acc = val_correct / len(val_loader.dataset)
        val_loss /= len(val_loader.dataset)

        print(f"Epoch [{epoch+1}/{epochs}] - "
              f"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | "
              f"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
train_vit(vit_model, train_loader, test_loader, device, epochs=27)

from sklearn.metrics import classification_report

vit_model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = vit_model(images)
        preds = torch.argmax(outputs, dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=train_dataset.classes))

# In your training notebook:
torch.save({
    'model_state_dict': vit_model.state_dict(),
    'model_architecture': 'vit_small_patch16_224',
    'num_classes': 4
}, "vit_ecg_model.pth")
print("üíæ Model saved as vit_ecg_model.pth")

import timm
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === Recreate a matching ViT model ===
# Your state_dict has embed_dim = 192 ‚Üí vit_tiny_patch16_224 fits
vit_model = timm.create_model("vit_tiny_patch16_224", pretrained=False, num_classes=4)
vit_model.to(device)

# Set up loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(vit_model.parameters(), lr=1e-4)

start_epoch = 28
end_epoch = 33  # To include 5 more epochs

for epoch in range(start_epoch, end_epoch):
    print(f"\nüîÅ Epoch {epoch}/{end_epoch - 1}")
    vit_model.train()
    total_loss, correct, total = 0.0, 0, 0

    for images, labels in tqdm(train_loader):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = vit_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * images.size(0)
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    train_acc = correct / total
    avg_loss = total_loss / total
    print(f"‚úÖ Epoch {epoch}: Loss = {avg_loss:.4f}, Accuracy = {train_acc:.4f}")

!cp vit_ecg_model.pth "/content/drive/MyDrive/"

import os

image_folder = "/content/drive/MyDrive/ecg_dataset/train/Normal Person ECG Images (284x12=3408)/"
print("‚úÖ Sample image files:")
print(os.listdir(image_folder)[:5])  # Show first 5 image files

import pandas as pd

# Load tabular data
df = pd.read_csv("/content/Cardiovascular Disease dataset.csv", sep=';')

# Format ID to match image filenames (like "001")
df['id'] = df['id'].astype(str).str.zfill(3)  # pad with zeros if needed

import os

image_dir = "/content/drive/MyDrive/ecg_dataset/train/Normal Person ECG Images (284x12=3408)"  # example folder
image_files = [f.split('.')[0] for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg'))]

matched = df['id'].isin(image_files)
print(f"‚úÖ Matched patients: {matched.sum()} out of {len(df)}")

# Optionally filter for only matched records
matched_df = df[matched].reset_index(drop=True)

from pytorch_tabnet.tab_model import TabNetClassifier

# Recreate TabNet model
tabnet_model = TabNetClassifier()
tabnet_model.load_model("/content/drive/MyDrive/tabnet_model.zip")  # adjust path if needed

vit_model = timm.create_model("vit_tiny_patch16_224", pretrained=False, num_classes=4)

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Image transform (must match training time!)
image_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# üîÅ Update this path to your test set location
test_path = "/content/drive/MyDrive/ecg_dataset/test"

# Load test set
test_dataset = datasets.ImageFolder(root=test_path, transform=image_transforms)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

import torch.nn.functional as F
vit_probs = []

vit_model.eval()

with torch.no_grad():
    for images, _ in test_loader:
        images = images.to(device)
        outputs = vit_model(images)
        probs = F.softmax(outputs, dim=1)
        vit_probs.extend(probs.cpu().numpy())

import numpy as np
vit_probs = np.array(vit_probs)
print("‚úÖ ViT prediction shape:", vit_probs.shape)

import numpy as np
np.save("/content/drive/MyDrive/vit_probs.npy", vit_probs)
print("‚úÖ Saved vit_probs to Drive")

# Predict class probabilities from TabNet
tabnet_probs = tabnet_model.predict_proba(X_test)

print("‚úÖ TabNet prediction shape:", tabnet_probs.shape)

import numpy as np

# Make sure both are NumPy arrays
vit_probs = np.array(vit_probs)       # shape: (n_samples, 4)
tabnet_probs = np.array(tabnet_probs) # shape: (n_samples, 2)

# Truncate to same number of samples if needed
min_len = min(len(vit_probs), len(tabnet_probs))
vit_probs = vit_probs[:min_len]
tabnet_probs = tabnet_probs[:min_len]

# Concatenate along axis 1 ‚Üí shape: (n_samples, 6)
fusion_input = np.concatenate([vit_probs, tabnet_probs], axis=1)
print("‚úÖ Fusion input shape:", fusion_input.shape)

y_true = np.array(y_test)[:min_len]
print("‚úÖ Labels shape:", y_true.shape)

from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, accuracy_score

# Train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(fusion_input, y_true, test_size=0.2, random_state=42)

# Build and train the MLP fusion model
fusion_model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000)

fusion_model.fit(X_train, y_train)

# Predict on test set
y_pred = fusion_model.predict(X_test)

# Evaluate
acc = accuracy_score(y_test, y_pred)
print(f"üéØ Fusion Classifier Accuracy: {acc:.4f}")
print("\nüìä Classification Report:\n", classification_report(y_test, y_pred))

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

xgb_fusion = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
xgb_fusion.fit(X_train, y_train)

y_pred_xgb = xgb_fusion.predict(X_test)
acc = accuracy_score(y_test, y_pred_xgb)

print(f"üå≤ XGBoost Fusion Accuracy: {acc:.4f}")
print(classification_report(y_test, y_pred_xgb))

import joblib
joblib.dump(fusion_model, "/content/drive/MyDrive/fusion_model.pkl")

!pip install gradio

# In your deployment code:
checkpoint = torch.load("/content/drive/MyDrive/vit_ecg_model.pth",
                       map_location="cpu",
                       weights_only=True)
vit_model = timm.create_model(checkpoint['model_architecture'],
                            pretrained=False,
                            num_classes=checkpoint['num_classes'])
vit_model.load_state_dict(checkpoint['model_state_dict'])
vit_model.eval()

import torch

checkpoint = torch.load("/content/drive/MyDrive/vit_ecg_model.pth", map_location="cpu")

# Print keys inside the checkpoint
print("Checkpoint keys:", checkpoint.keys())
print("Architecture info:", checkpoint.get("model_architecture", "Not found"))
print("Num classes:", checkpoint.get("num_classes", "Not found"))

import torch
import pickle
import timm  # Required for ViT model

# Load the checkpoint
checkpoint_path = "/content/drive/MyDrive/vit_ecg_model.pth"
checkpoint = torch.load(checkpoint_path, map_location="cpu")

# Extract details
architecture = checkpoint["model_architecture"]
num_classes = checkpoint["num_classes"]
state_dict = checkpoint["model_state_dict"]

# Rebuild the model using timm
vit_model = timm.create_model(architecture, pretrained=False, num_classes=num_classes)

# Load the state dict
vit_model.load_state_dict(state_dict)
vit_model.eval()

# Save as pickle
pkl_path = "/content/drive/MyDrive/vit_ecg_model.pkl"
with open(pkl_path, "wb") as f:
    pickle.dump(vit_model, f)

print(f"‚úÖ ViT model saved as: {pkl_path}")

from pytorch_tabnet.tab_model import TabNetClassifier
import pickle

# Step 1: Load the TabNet model from the zip file
tabnet_model = TabNetClassifier()
tabnet_model.load_model("/content/drive/MyDrive/tabnet_model.zip")

# Step 2: Save the model as a pickle file
pkl_path = "/content/drive/MyDrive/tabnet_model.pkl"
with open(pkl_path, "wb") as f:
    pickle.dump(tabnet_model, f)

print(f"‚úÖ TabNet model saved as pickle at: {pkl_path}")

!pip install gradio

import gradio as gr
from PIL import Image
import numpy as np
import torch
import pickle
import timm
# --- Load models ---
with open("/content/drive/MyDrive/vit_ecg_model.pkl", "rb") as f:
    vit_model = pickle.load(f)

with open("/content/drive/MyDrive/tabnet_model.pkl", "rb") as f:
    tabnet_model = pickle.load(f)

with open("/content/drive/MyDrive/fusion_model.pkl", "rb") as f:
    fusion_model = pickle.load(f)

vit_model.eval()
vit_model.to('cpu')

# --- Class mappings ---
vit_class_labels = [
    "Myocardial Infarction Patient",
    "History of Myocardial Infarction",
    "Abnormal Heartbeat",
    "Normal Person"
]

tabnet_class_labels = {
    1: "Normal",
    0: "Abnormal"
}

# --- Prediction function ---
def predict_combined_final(
    image: Image.Image,
    age, gender, height, weight, ap_hi, ap_lo,
    cholesterol, gluc, smoke, alco, active
):
    try:
        tabular_input = [
            0.0,  # ID (placeholder)
            float(age), float(gender), float(height), float(weight),
            float(ap_hi), float(ap_lo), float(cholesterol), float(gluc),
            float(smoke), float(alco), float(active)
        ]

        # --- Process image ---
        image = image.resize((224, 224))
        image_np = np.array(image).astype(np.float32) / 255.0

        if image_np.ndim == 2:
            image_np = np.stack([image_np]*3, axis=-1)
        elif image_np.shape[2] == 1:
            image_np = np.repeat(image_np, 3, axis=2)

        image_tensor = torch.tensor(image_np).permute(2, 0, 1).unsqueeze(0).float().to('cpu')

        with torch.no_grad():
            vit_logits = vit_model(image_tensor)
            if isinstance(vit_logits, dict) and "logits" in vit_logits:
                vit_logits = vit_logits["logits"]
            vit_probs = torch.softmax(vit_logits, dim=1).squeeze().cpu().numpy()

        # --- Predict with TabNet ---
        tabular_array = np.array([tabular_input], dtype=np.float32)
        tabnet_probs = tabnet_model.predict_proba(tabular_array)[0]

        # --- Concatenate probabilities for fusion model ---
        fusion_input = np.concatenate([vit_probs, tabnet_probs], axis=0).reshape(1, -1)

        # --- Final predictions with fusion model ---
        fusion_pred = fusion_model.predict(fusion_input)[0]
        # Map fusion model output to human-readable labels
        fusion_label = tabnet_class_labels.get(fusion_pred, "Unknown")


        # --- Return human-readable labels ---
        vit_pred_class = int(np.argmax(vit_probs))
        tabnet_pred_class = int(np.argmax(tabnet_probs))
        vit_label = vit_class_labels[vit_pred_class]
        tabnet_label = tabnet_class_labels[tabnet_pred_class]

        return (
            f"ü©∫ ViT Model Prediction: {vit_label} (Class {vit_pred_class})\n"
            f"üß¨ TabNet Model Prediction: {tabnet_label} (Class {tabnet_pred_class})\n"
            f"ÏúµÌï© Î™®Îç∏ ÏòàÏ∏°: {fusion_label} (Class {fusion_pred})"
        )

    except Exception as e:
        return f"‚ùå Error: {str(e)}"

# --- Gradio Interface ---
with gr.Blocks() as demo:
    gr.Markdown("## üß† ECG Image + Tabular Data Prediction")

    with gr.Row():
        img_input = gr.Image(type="pil", label="ECG Image")

        with gr.Column():
            age = gr.Number(label="Age")
            gender = gr.Number(label="Gender (0 or 1)")
            height = gr.Number(label="Height (cm)")
            weight = gr.Number(label="Weight (kg)")
            ap_hi = gr.Number(label="Systolic BP (ap_hi)")
            ap_lo = gr.Number(label="Diastolic BP (ap_lo)")
            cholesterol = gr.Number(label="Cholesterol (1-3)")
            gluc = gr.Number(label="Glucose (1-3)")
            smoke = gr.Number(label="Smoke (0 or 1)")
            alco = gr.Number(label="Alcohol (0 or 1)")
            active = gr.Number(label="Physical activity (0 or 1)")

    submit_btn = gr.Button("Submit")
    output_text = gr.Textbox(label="Prediction Result", lines=4)

    submit_btn.click(
        fn=predict_combined_final,
        inputs=[
            img_input, age, gender, height, weight, ap_hi, ap_lo,
            cholesterol, gluc, smoke, alco, active
        ],
        outputs=output_text
    )

# --- Launch the app ---
demo.launch()

# Commented out IPython magic to ensure Python compatibility.
# # Install required packages if not already installed
# !pip install streamlit pyngrok --quiet
# 
# # Save this script as `app.py`
# %%writefile app.py
# import streamlit as st
# from PIL import Image
# import numpy as np
# import torch
# import pickle
# 
# # --- Load models ---
# with open("/content/drive/MyDrive/vit_ecg_model.pkl", "rb") as f:
#     vit_model = pickle.load(f)
# 
# with open("/content/drive/MyDrive/tabnet_model.pkl", "rb") as f:
#     tabnet_model = pickle.load(f)
# 
# vit_model.eval()
# vit_model.to('cpu')
# 
# # --- Class mappings ---
# vit_class_labels = [
#     "Myocardial Infarction Patient",
#     "History of Myocardial Infarction",
#     "Abnormal Heartbeat",
#     "Normal Person"
# ]
# 
# tabnet_class_labels = {
#     1: "Normal",
#     0: "Abnormal"
# }
# 
# # --- Streamlit UI ---
# st.title("üß† ECG Image + Tabular Data Prediction")
# 
# uploaded_image = st.file_uploader("Upload ECG Image", type=["png", "jpg", "jpeg"])
# 
# st.markdown("### üìã Enter Tabular Patient Data")
# age = st.number_input("Age", min_value=0.0)
# gender = st.number_input("Gender (0 = Female, 1 = Male)", min_value=0.0, max_value=1.0)
# height = st.number_input("Height (cm)", min_value=0.0)
# weight = st.number_input("Weight (kg)", min_value=0.0)
# ap_hi = st.number_input("Systolic BP (ap_hi)", min_value=0.0)
# ap_lo = st.number_input("Diastolic BP (ap_lo)", min_value=0.0)
# cholesterol = st.number_input("Cholesterol (1-3)", min_value=1.0, max_value=3.0)
# gluc = st.number_input("Glucose (1-3)", min_value=1.0, max_value=3.0)
# smoke = st.number_input("Smoke (0 or 1)", min_value=0.0, max_value=1.0)
# alco = st.number_input("Alcohol (0 or 1)", min_value=0.0, max_value=1.0)
# active = st.number_input("Physical Activity (0 or 1)", min_value=0.0, max_value=1.0)
# 
# if st.button("Submit"):
#     try:
#         if uploaded_image is None:
#             st.error("Please upload an ECG image.")
#         else:
#             image = Image.open(uploaded_image).convert("RGB")
#             image = image.resize((224, 224))
#             image_np = np.array(image).astype(np.float32) / 255.0
# 
#             if image_np.ndim == 2:
#                 image_np = np.stack([image_np]*3, axis=-1)
#             elif image_np.shape[2] == 1:
#                 image_np = np.repeat(image_np, 3, axis=2)
# 
#             image_tensor = torch.tensor(image_np).permute(2, 0, 1).unsqueeze(0).float().to('cpu')
# 
#             with torch.no_grad():
#                 vit_logits = vit_model(image_tensor)
#                 if isinstance(vit_logits, dict) and "logits" in vit_logits:
#                     vit_logits = vit_logits["logits"]
#                 vit_probs = torch.softmax(vit_logits, dim=1).squeeze().cpu().numpy()
# 
#             vit_pred_class = int(np.argmax(vit_probs))
#             vit_label = vit_class_labels[vit_pred_class]
# 
#             tabular_input = [
#                 0.0, float(age), float(gender), float(height), float(weight),
#                 float(ap_hi), float(ap_lo), float(cholesterol), float(gluc),
#                 float(smoke), float(alco), float(active)
#             ]
#             tabular_array = np.array([tabular_input], dtype=np.float32)
#             tabnet_probs = tabnet_model.predict_proba(tabular_array)[0]
#             tabnet_pred_class = int(np.argmax(tabnet_probs))
#             tabnet_label = tabnet_class_labels[tabnet_pred_class]
# 
#             st.success(f"ü©∫ ViT Model Prediction: **{vit_label}** (Class {vit_pred_class})")
#             st.success(f"üß¨ TabNet Model Prediction: **{tabnet_label}** (Class {tabnet_pred_class})")
# 
#     except Exception as e:
#         st.error(f"Error during prediction: {e}")
#

!pip install streamlit pyngrok --quiet

from pyngrok import ngrok

# Paste your own authtoken here (from https://dashboard.ngrok.com/get-started/your-authtoken)
ngrok.set_auth_token("2xm68p1bmXwvBZPiqr8aI0EDBx0_2rvYpYjV3NcdM5ipnr52u")
#!ngrok config add-authtoken 2xm68p1bmXwvBZPiqr8aI0EDBx0_2rvYpYjV3NcdM5ipnr52u

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# from PIL import Image
# import numpy as np
# import torch
# import pickle
# 
# # --- Load models ---
# with open("/content/drive/MyDrive/vit_ecg_model.pkl", "rb") as f:
#     vit_model = pickle.load(f)
# 
# with open("/content/drive/MyDrive/tabnet_model.pkl", "rb") as f:
#     tabnet_model = pickle.load(f)
# 
# vit_model.eval()
# vit_model.to("cpu")
# 
# # --- Class mappings ---
# vit_class_labels = [
#     "Myocardial Infarction Patient",
#     "History of Myocardial Infarction",
#     "Abnormal Heartbeat",
#     "Normal Person"
# ]
# 
# tabnet_class_labels = {
#     0: "Normal",
#     1: "Abnormal"
# }
# 
# # --- Prediction function ---
# def predict_combined_final(image, age, gender, height, weight, ap_hi, ap_lo,
#                            cholesterol, gluc, smoke, alco, active):
#     try:
#         tabular_input = [
#             0.0,  # ID placeholder
#             float(age), float(gender), float(height), float(weight),
#             float(ap_hi), float(ap_lo), float(cholesterol), float(gluc),
#             float(smoke), float(alco), float(active)
#         ]
# 
#         # --- Process image ---
#         image = image.resize((224, 224))
#         image_np = np.array(image).astype(np.float32) / 255.0
# 
#         if image_np.ndim == 2:
#             image_np = np.stack([image_np]*3, axis=-1)
#         elif image_np.shape[2] == 1:
#             image_np = np.repeat(image_np, 3, axis=2)
# 
#         image_tensor = torch.tensor(image_np).permute(2, 0, 1).unsqueeze(0).float().to("cpu")
# 
#         with torch.no_grad():
#             vit_logits = vit_model(image_tensor)
#             if isinstance(vit_logits, dict) and "logits" in vit_logits:
#                 vit_logits = vit_logits["logits"]
#             vit_probs = torch.softmax(vit_logits, dim=1).squeeze().cpu().numpy()
# 
#         # --- TabNet Prediction ---
#         tabular_array = np.array([tabular_input], dtype=np.float32)
#         tabnet_probs = tabnet_model.predict_proba(tabular_array)[0]
# 
#         vit_pred_class = int(np.argmax(vit_probs))
#         tabnet_pred_class = int(np.argmax(tabnet_probs))
# 
#         vit_label = vit_class_labels[vit_pred_class]
#         tabnet_label = tabnet_class_labels[tabnet_pred_class]
# 
#         return (
#             f"ü©∫ ViT Model Prediction: {vit_label} (Class {vit_pred_class})\n"
#             f"üß¨ TabNet Model Prediction: {tabnet_label} (Class {tabnet_pred_class})"
#         )
# 
#     except Exception as e:
#         return f"‚ùå Error: {str(e)}"
# 
# 
# # --- Streamlit UI ---
# st.title("üß† ECG + Tabular Data Diagnosis")
# 
# uploaded_image = st.file_uploader("Upload ECG Image", type=["png", "jpg", "jpeg"])
# if uploaded_image:
#     image = Image.open(uploaded_image)
#     st.image(image, caption="Uploaded ECG", width=300)
# else:
#     image = None
# 
# st.subheader("Patient Details")
# age = st.number_input("Age", min_value=1, max_value=120)
# gender = st.selectbox("Gender", [0, 1])
# height = st.number_input("Height (cm)", min_value=50, max_value=250)
# weight = st.number_input("Weight (kg)", min_value=10, max_value=300)
# ap_hi = st.number_input("Systolic BP", min_value=50, max_value=250)
# ap_lo = st.number_input("Diastolic BP", min_value=30, max_value=150)
# cholesterol = st.selectbox("Cholesterol (1: normal, 2: above normal, 3: well above)", [1, 2, 3])
# gluc = st.selectbox("Glucose (1: normal, 2: above normal, 3: well above)", [1, 2, 3])
# smoke = st.selectbox("Smoker", [0, 1])
# alco = st.selectbox("Alcohol Intake", [0, 1])
# active = st.selectbox("Physically Active", [0, 1])
# 
# if st.button("Submit"):
#     if image:
#         result = predict_combined_final(image, age, gender, height, weight, ap_hi, ap_lo,
#                                         cholesterol, gluc, smoke, alco, active)
#         st.success(result)
#     else:
#         st.error("Please upload an ECG image.")
#

import threading
import time
import os

def run_streamlit():
    os.system('streamlit run app.py')

# Start Streamlit in background
threading.Thread(target=run_streamlit).start()

# Wait briefly for app to start
time.sleep(3)

# Connect ngrok to the correct localhost address
public_url = ngrok.connect(addr="8501", proto="http")
print("üöÄ Streamlit app is live at:", public_url)

# Install required packages
!pip install streamlit pyngrok --quiet

# Write your streamlit app to a file (if not already)
with open("app.py", "w") as f:
    f.write("""
import streamlit as st

st.title("My Streamlit App")
st.write("‚úÖ This is working!")
""")

# Set up ngrok
from pyngrok import ngrok

# Kill previous tunnels
ngrok.kill()

# Create tunnel to port 8501
public_url = ngrok.connect(port=8501)
print("üåç Public URL:", public_url)

# Run streamlit in background
!streamlit run app.py &